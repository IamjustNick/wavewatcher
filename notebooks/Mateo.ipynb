{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-28 12:42:55.396493: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-28 12:42:56.209489: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-28 12:42:56.209573: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-11-28 12:42:56.316370: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-28 12:42:59.041327: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-28 12:42:59.041586: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-28 12:42:59.041602: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import Sequential, layers\n",
    "from tensorflow.keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First version of the model1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- strides define kernel moving by a fixed number of pixels in each direction, the higher the value the less we focus on each and every part of the image\n",
    "- input shape depends on preprocessing, nevertheless, in the lecture they suggest less than 256 pixels. We also agreed to make images black&white. So the firt input_shape is the largest possible. \n",
    "- we have decided not to perform padding, as we do not care about borders of our images\n",
    "- we add pooling layer after every convolutional layer in order to decrease the output shape. That is a good practice according to the lecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are some variables that we will be using in all of the models\n",
    "INPUT_SHAPE = (255, 255, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the most basic model, the minimum that we need to use\n",
    "model1 = Sequential()\n",
    "model1.add(layers.Conv2D(16, (3,3), input_shape= INPUT_SHAPE, padding='valid', activation=\"relu\"))\n",
    "model1.add(layers.Flatten())\n",
    "model1.add(layers.Dense(3, activation='softmax'))\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The more advanced model with two layers, based on the lecture suggestions\n",
    "model2 = Sequential()\n",
    "model2.add(layers.Conv2D(16, (3,3), input_shape= INPUT_SHAPE, padding='valid', activation=\"relu\"))\n",
    "model2.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "model2.add(layers.Conv2D(32, (2,2), padding='valid', activation=\"relu\"))\n",
    "model2.add(layers.MaxPool2D(pool_size=(2,2))) \n",
    "\n",
    "model2.add(layers.Flatten())\n",
    "model2.add(layers.Dense(16, activation='relu')) \n",
    "model2.add(layers.Dense(3, activation='softmax'))\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As the boss said: we are optimizing for recall, so we do not skip any good wave, rather than waste time for bad wave\n",
    "\n",
    "def compile_model(model):\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"recall\"])\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Transfer Learning with VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_transfer_model():\n",
    "    \n",
    "    model = VGG16(weights=\"imagenet\", include_top=False, input_shape= INPUT_SHAPE)\n",
    "    model.trainable = False\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = load_transfer_model()\n",
    "flattening_layer = layers.Flatten()\n",
    "dense_layer = layers.Dense(SOME_NUMBER_1, activation='relu')\n",
    "prediction_layer = layers.Dense(SOME_NUMBER_2, activation='softmax')\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  base_model,\n",
    "  flattening_layer,\n",
    "  dense_layer,\n",
    "  prediction_layer\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit ('shims')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "84d9a2387a2e320b0513647598f53aca0d3d105be8af92236c422cd6b257ff2d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
